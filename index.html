<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Physically Accurate Head Tracking</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #111; font-family: sans-serif; }
        
        /* Main 3D Canvas */
        #canvas-container { width: 100vw; height: 100vh; position: absolute; top: 0; left: 0; z-index: 1; }

        /* UI Overlays */
        #info {
            position: absolute; top: 10px; left: 10px; z-index: 10;
            color: lime; font-family: monospace; background: rgba(0,0,0,0.5); padding: 10px;
            pointer-events: none;
        }

        #webcam-preview {
            position: absolute; bottom: 10px; left: 10px; width: 200px; z-index: 10;
            border: 1px solid #555; transform: scaleX(-1); opacity: 0.8;
        }

        #loading {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            color: white; font-size: 1.2rem; z-index: 20;
        }
    </style>
</head>
<body>

    <div id="loading">Initializing Neural Network...</div>
    <div id="info">Waiting for face...</div>
    <video id="webcam-preview" autoplay playsinline muted></video>
    <div id="canvas-container"></div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
                "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/+esm"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { STLLoader } from 'three/addons/loaders/STLLoader.js';
        import { FilesetResolver, FaceLandmarker } from '@mediapipe/tasks-vision';

        // ==========================================
        // 1. PHYSICAL CONFIGURATION (MEASURE THESE)
        // ==========================================
        const CONFIG = {
            WEBCAM_FOV_Y: 55,     // Webcam Vertical Field of View (Degrees). 
                                  // Most laptops are ~50-60. iPhones ~60.
            REAL_IPD_CM: 6.4,     // Distance between your pupils in cm. (Avg is 6.3 - 6.5)
            SMOOTHING: 0.2       // 0.01 (very smooth/slow) to 1.0 (instant/jittery)
        };

        // ==========================================
        // 2. THREE.JS SETUP
        // ==========================================
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x111111);

        const camera = new THREE.PerspectiveCamera(CONFIG.WEBCAM_FOV_Y, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.getElementById('canvas-container').appendChild(renderer.domElement);

        // Lighting
        const light = new THREE.DirectionalLight(0xffffff, 2);
        light.position.set(10, 20, 15);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0xffffff, 0.3));

        // Helper Grid (1 unit = 1cm) -> 20cm grid
        const grid = new THREE.GridHelper(50, 50, 0x444444, 0x222222);
        scene.add(grid);

        // Load STL or Fallback
        const stlLoader = new STLLoader();
        stlLoader.load('./model.stl', (geometry) => {
            geometry.center();
            geometry.computeBoundingBox();
            
            // Normalize size: Scale object to be 10cm wide
            const width = geometry.boundingBox.max.x - geometry.boundingBox.min.x;
            const scaleFactor = 10 / width; 
            
            const material = new THREE.MeshNormalMaterial();
            const mesh = new THREE.Mesh(geometry, material);
            mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);
            mesh.rotation.x = -Math.PI / 2;
            scene.add(mesh);
        }, undefined, () => {
            // Fallback Box (10x10x10 cm)
            const box = new THREE.Mesh(
                new THREE.BoxGeometry(10, 10, 10),
                new THREE.MeshNormalMaterial({ wireframe: false })
            );
            scene.add(box);
        });

        // ==========================================
        // 3. MATH HELPERS (PINHOLE MODEL)
        // ==========================================
        
        // Calculate Focal Length in "Unit Height"
        // If image height is 1.0, what is focal length?
        // tan(theta/2) = (height/2) / focal_length
        // focal_length = 0.5 / tan(FOV/2)
        const fovRad = (CONFIG.WEBCAM_FOV_Y * Math.PI) / 180;
        const focalLengthNorm = 0.5 / Math.tan(fovRad / 2);

        // State for smoothing
        const currentPos = new THREE.Vector3(0, 0, 60); // Start 60cm back
        const targetPos = new THREE.Vector3(0, 0, 60);

        // ==========================================
        // 4. MEDIAPIPE LOGIC
        // ==========================================
        const video = document.getElementById('webcam-preview');
        const infoDiv = document.getElementById('info');
        let faceLandmarker;

        async function initVision() {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                    delegate: "GPU"
                },
                runningMode: "VIDEO",
                numFaces: 1
            });
            
            document.getElementById('loading').style.display = 'none';
            
            navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } }).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", renderLoop);
            });
        }

        // ==========================================
        // 5. MAIN LOOP
        // ==========================================
        let lastVideoTime = -1;

        function renderLoop() {
            // 1. Detect Face
            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                const results = faceLandmarker.detectForVideo(video, performance.now());

                if (results.faceLandmarks.length > 0) {
                    const landmarks = results.faceLandmarks[0];

                    // --- PHYSICS CALCULATION START ---
                    
                    // Left Eye: Index 468 (Iris Center) or 33 (Corner)
                    // Let's use pupil centers: 468 (Left), 473 (Right)
                    const leftPupil = landmarks[468];
                    const rightPupil = landmarks[473];

                    // Calculate distance between pupils in NORMALIZED coords (0..1)
                    // We must correct for aspect ratio because pixels aren't square in 0..1 space
                    const aspect = video.videoWidth / video.videoHeight;
                    
                    const dx = (leftPupil.x - rightPupil.x) * aspect;
                    const dy = (leftPupil.y - rightPupil.y);
                    const distScreen = Math.sqrt(dx*dx + dy*dy); // Distance in "screen height units"

                    // Z = (Real Size * Focal Length) / Image Size
                    const zCm = (CONFIG.REAL_IPD_CM * focalLengthNorm) / distScreen;

                    // X and Y position
                    // Midpoint of eyes in 0..1
                    const midX = (leftPupil.x + rightPupil.x) / 2;
                    const midY = (leftPupil.y + rightPupil.y) / 2;

                    // Convert to centered coordinates [-0.5, 0.5]
                    // Multiply X by aspect ratio
                    // Invert X because camera moves OPPOSITE to subject in frame
                    // (Subject moves Left -> Image moves Right -> Camera must move Left)
                    const xScreen = (0.5 - midX) * aspect; 
                    const yScreen = (0.5 - midY); // +Y is Up

                    // Project to World Coordinates using similar triangles
                    // X_world / Z_world = x_screen / f
                    const xCm = (xScreen * zCm) / focalLengthNorm;
                    const yCm = (yScreen * zCm) / focalLengthNorm;

                    targetPos.set(xCm, yCm, zCm);
                    
                    infoDiv.innerText = `Pos: ${xCm.toFixed(1)}, ${yCm.toFixed(1)}, ${zCm.toFixed(1)} cm`;
                    // --- PHYSICS CALCULATION END ---
                }
            }

            // 2. Smooth Movement
            currentPos.lerp(targetPos, CONFIG.SMOOTHING);

            // 3. Update Camera
            camera.position.copy(currentPos);
            camera.lookAt(0, 0, 0); // Always look at object

            renderer.render(scene, camera);
            requestAnimationFrame(renderLoop);
        }

        // Handle Window Resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        initVision();
    </script>
</body>
</html>
